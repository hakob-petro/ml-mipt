{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFmOh482SyEF"
      },
      "source": [
        "## Lab 2\n",
        "### Part 2: Dealing with overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjzAuO3oSvsI"
      },
      "source": [
        "Today we work with [Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist) (*hint: it is available in `torchvision`*).\n",
        "\n",
        "Your goal for today:\n",
        "1. Train a FC (fully-connected) network that achieves >= 0.885 test accuracy.\n",
        "2. Cause considerable overfitting by modifying the network (e.g. increasing the number of network parameters and/or layers) and demonstrate in in the appropriate way (e.g. plot loss and accurasy on train and validation set w.r.t. network complexity).\n",
        "3. Try to deal with overfitting (at least partially) by using regularization techniques (Dropout/Batchnorm/...) and demonstrate the results.\n",
        "\n",
        "__Please, write a small report describing your ideas, tries and achieved results in the end of this file.__\n",
        "\n",
        "*Note*: Tasks 2 and 3 are interrelated, in task 3 your goal is to make the network from task 2 less prone to overfitting. Task 1 is independent from 2 and 3.\n",
        "\n",
        "*Note 2*: We recomment to use Google Colab or other machine with GPU acceleration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_KBld6VOSwhW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchsummary\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdLOG0XqS_g5",
        "outputId": "c022036e-fd25-40bf-ebda-f1658b48010a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory fmnist already exists!\n"
          ]
        }
      ],
      "source": [
        "# Technical function\n",
        "def mkdir(path):\n",
        "    if not os.path.exists(root_path):\n",
        "        os.mkdir(root_path)\n",
        "        print('Directory', path, 'is created!')\n",
        "    else:\n",
        "        print('Directory', path, 'already exists!')\n",
        "        \n",
        "root_path = 'fmnist'\n",
        "mkdir(root_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qt6LE7XaTDT9"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "download = True\n",
        "valid_size = 0.2\n",
        "num_workers = 10\n",
        "train_transform = transforms.ToTensor()\n",
        "test_transform = transforms.ToTensor()\n",
        "transforms.Compose((transforms.ToTensor()))\n",
        "\n",
        "\n",
        "fmnist_dataset_train = torchvision.datasets.FashionMNIST(root_path, \n",
        "                                                        train=True, \n",
        "                                                        transform=train_transform,\n",
        "                                                        target_transform=None,\n",
        "                                                        download=download)\n",
        "fmnist_dataset_test = torchvision.datasets.FashionMNIST(root_path, \n",
        "                                                       train=False, \n",
        "                                                       transform=test_transform,\n",
        "                                                       target_transform=None,\n",
        "                                                       download=download)\n",
        "\n",
        "# Obtain training indices that will be used for validation\n",
        "num_train = len(fmnist_dataset_train)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(valid_size * num_train))\n",
        "train_index, valid_index = indices[split:], indices[:split]\n",
        "\n",
        "# Define samplers for obtaining training and validation batches\n",
        "train_sampler = SubsetRandomSampler(train_index)\n",
        "valid_sampler = SubsetRandomSampler(valid_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71YP0SPwTIxD",
        "outputId": "4807bc12-dbcb-4430-c9cd-5fc8abb9e6b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "source": [
        "train_loader = torch.utils.data.DataLoader(fmnist_dataset_train, \n",
        "                                           batch_size=128,\n",
        "                                           sampler=train_sampler,\n",
        "                                           num_workers=num_workers)\n",
        "\n",
        "valid_loader = torch.utils.data.DataLoader(fmnist_dataset_train,\n",
        "                                           batch_size=128,\n",
        "                                           sampler=valid_sampler,\n",
        "                                           num_workers=num_workers)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(fmnist_dataset_test,\n",
        "                                          batch_size=256,\n",
        "                                          shuffle=False,\n",
        "                                          num_workers=num_workers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_YFmF7NTWrQ",
        "outputId": "d21879dd-e4df-4e3f-914f-365f848a14dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "len(fmnist_dataset_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHca15bOTY4B",
        "outputId": "294db51f-e898-4d06-f9f0-27fee3e3d733"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128])\n",
            "128\n"
          ]
        }
      ],
      "source": [
        "for img, label in train_loader:\n",
        "    print(img.shape)\n",
        "#     print(img)\n",
        "    print(label.shape)\n",
        "    print(label.size(0))\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "392xt-lP11Td",
        "outputId": "92594977-a904-4fed-f108-9de60e6c3303"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(np.squeeze(img[0].permute(1, 2, 0)), cmap='Greys')\n",
        "\n",
        "next(iter(train_loader))[1].size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6OOOffHTfX5"
      },
      "source": [
        "### Task 1\n",
        "Train a network that achieves $\\geq 0.885$ test accuracy. It's fine to use only Linear (`nn.Linear`) layers and activations/dropout/batchnorm. Convolutional layers might be a great use, but we will meet them a bit later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ftpkTjxlTcFx"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class TinyNeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_shape=28*28, num_classes=10, input_channels=1):\n",
        "        super(self.__class__, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(input_shape, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(512, num_classes),\n",
        "            nn.LogSoftmax()\n",
        "        )\n",
        "        \n",
        "    def forward(self, inp):       \n",
        "        out = self.model(inp)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HttcCR6w11Te",
        "outputId": "f57767f5-1cf0-496e-cb1e-f2fafc7c148b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "           Flatten-1                  [-1, 784]               0\n",
            "            Linear-2                  [-1, 512]         401,920\n",
            "       BatchNorm1d-3                  [-1, 512]           1,024\n",
            "              ReLU-4                  [-1, 512]               0\n",
            "           Dropout-5                  [-1, 512]               0\n",
            "            Linear-6                  [-1, 512]         262,656\n",
            "       BatchNorm1d-7                  [-1, 512]           1,024\n",
            "              ReLU-8                  [-1, 512]               0\n",
            "           Dropout-9                  [-1, 512]               0\n",
            "           Linear-10                   [-1, 10]           5,130\n",
            "       LogSoftmax-11                   [-1, 10]               0\n",
            "================================================================\n",
            "Total params: 671,754\n",
            "Trainable params: 671,754\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.04\n",
            "Params size (MB): 2.56\n",
            "Estimated Total Size (MB): 2.60\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        }
      ],
      "source": [
        "torchsummary.summary(TinyNeuralNetwork().to(device), (28*28,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "544PGKEnjPr5"
      },
      "source": [
        "Your experiments come here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3POFj90Ti-6",
        "outputId": "7a5a1e34-22bc-400f-8f40-8df76ab27948",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.729784 \tValidation Loss: 0.003308\n",
            "Validation loss decreased (inf --> 0.003308).  Saving model ...\n",
            "Epoch: 2 \tTraining Loss: 0.474706 \tValidation Loss: 0.003205\n",
            "Validation loss decreased (0.003308 --> 0.003205).  Saving model ...\n",
            "Epoch: 3 \tTraining Loss: 0.421036 \tValidation Loss: 0.002172\n",
            "Validation loss decreased (0.003205 --> 0.002172).  Saving model ...\n",
            "Epoch: 4 \tTraining Loss: 0.391765 \tValidation Loss: 0.002532\n",
            "Epoch: 5 \tTraining Loss: 0.371240 \tValidation Loss: 0.003081\n",
            "Epoch: 6 \tTraining Loss: 0.356071 \tValidation Loss: 0.003178\n",
            "Epoch: 7 \tTraining Loss: 0.341203 \tValidation Loss: 0.004407\n",
            "Epoch: 8 \tTraining Loss: 0.329372 \tValidation Loss: 0.002953\n",
            "Epoch: 9 \tTraining Loss: 0.318351 \tValidation Loss: 0.003635\n",
            "Epoch: 10 \tTraining Loss: 0.310302 \tValidation Loss: 0.002327\n",
            "Epoch: 11 \tTraining Loss: 0.299797 \tValidation Loss: 0.002222\n",
            "Epoch: 12 \tTraining Loss: 0.291960 \tValidation Loss: 0.002432\n",
            "Epoch: 13 \tTraining Loss: 0.283092 \tValidation Loss: 0.003100\n",
            "Epoch: 14 \tTraining Loss: 0.277402 \tValidation Loss: 0.002822\n",
            "Epoch: 15 \tTraining Loss: 0.272346 \tValidation Loss: 0.003453\n",
            "Epoch: 16 \tTraining Loss: 0.263515 \tValidation Loss: 0.003023\n",
            "Epoch: 17 \tTraining Loss: 0.258398 \tValidation Loss: 0.003014\n",
            "Epoch: 18 \tTraining Loss: 0.250783 \tValidation Loss: 0.002691\n",
            "Epoch: 19 \tTraining Loss: 0.246049 \tValidation Loss: 0.001921\n",
            "Validation loss decreased (0.002172 --> 0.001921).  Saving model ...\n",
            "Epoch: 20 \tTraining Loss: 0.242040 \tValidation Loss: 0.002217\n",
            "Epoch: 21 \tTraining Loss: 0.237662 \tValidation Loss: 0.002680\n",
            "Epoch: 22 \tTraining Loss: 0.227013 \tValidation Loss: 0.002284\n",
            "Epoch: 23 \tTraining Loss: 0.223937 \tValidation Loss: 0.003033\n",
            "Epoch: 24 \tTraining Loss: 0.220528 \tValidation Loss: 0.001543\n",
            "Validation loss decreased (0.001921 --> 0.001543).  Saving model ...\n",
            "Epoch: 25 \tTraining Loss: 0.219430 \tValidation Loss: 0.002882\n",
            "Epoch: 26 \tTraining Loss: 0.211417 \tValidation Loss: 0.001492\n",
            "Validation loss decreased (0.001543 --> 0.001492).  Saving model ...\n",
            "Epoch: 27 \tTraining Loss: 0.208405 \tValidation Loss: 0.002396\n",
            "Epoch: 28 \tTraining Loss: 0.203632 \tValidation Loss: 0.001873\n",
            "Epoch: 29 \tTraining Loss: 0.200005 \tValidation Loss: 0.002186\n",
            "Epoch: 30 \tTraining Loss: 0.196601 \tValidation Loss: 0.002952\n",
            "Epoch: 31 \tTraining Loss: 0.189958 \tValidation Loss: 0.002893\n",
            "Epoch: 32 \tTraining Loss: 0.188431 \tValidation Loss: 0.002078\n",
            "Epoch: 33 \tTraining Loss: 0.183087 \tValidation Loss: 0.001761\n",
            "Epoch: 34 \tTraining Loss: 0.179026 \tValidation Loss: 0.002424\n",
            "Epoch: 35 \tTraining Loss: 0.177855 \tValidation Loss: 0.002057\n",
            "Epoch: 36 \tTraining Loss: 0.172139 \tValidation Loss: 0.002446\n",
            "Epoch: 37 \tTraining Loss: 0.169504 \tValidation Loss: 0.003450\n",
            "Epoch: 38 \tTraining Loss: 0.168264 \tValidation Loss: 0.002766\n",
            "Epoch: 39 \tTraining Loss: 0.161021 \tValidation Loss: 0.003010\n",
            "Epoch: 40 \tTraining Loss: 0.159836 \tValidation Loss: 0.002668\n",
            "Epoch: 41 \tTraining Loss: 0.156908 \tValidation Loss: 0.001471\n",
            "Validation loss decreased (0.001492 --> 0.001471).  Saving model ...\n",
            "Epoch: 42 \tTraining Loss: 0.153360 \tValidation Loss: 0.002645\n",
            "Epoch: 43 \tTraining Loss: 0.151658 \tValidation Loss: 0.002898\n",
            "Epoch: 44 \tTraining Loss: 0.146875 \tValidation Loss: 0.002118\n",
            "Epoch: 45 \tTraining Loss: 0.146350 \tValidation Loss: 0.002901\n",
            "Epoch: 46 \tTraining Loss: 0.143536 \tValidation Loss: 0.003021\n",
            "Epoch: 47 \tTraining Loss: 0.141993 \tValidation Loss: 0.002026\n",
            "Epoch: 48 \tTraining Loss: 0.135636 \tValidation Loss: 0.002660\n",
            "Epoch: 49 \tTraining Loss: 0.132592 \tValidation Loss: 0.002418\n",
            "Epoch: 50 \tTraining Loss: 0.131455 \tValidation Loss: 0.002211\n",
            "CPU times: user 1min 49s, sys: 1min 14s, total: 3min 4s\n",
            "Wall time: 8min 20s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "model = TinyNeuralNetwork().to(device)\n",
        "opt = torch.optim.SGD(model.parameters(),lr = 0.01)\n",
        "loss_func = nn.NLLLoss()\n",
        "\n",
        "n_epochs = 50\n",
        "valid_loss_min = np.Inf  \n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss = 0\n",
        "    valid_loss = 0\n",
        "    \n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    model.train()\n",
        "    for data,label in train_loader:\n",
        "        opt.zero_grad()\n",
        "        \n",
        "        # Forward\n",
        "        output = model(data.to(device))\n",
        "        loss = loss_func(output,label.to(device))\n",
        "        \n",
        "        # Backward\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        \n",
        "        # update running training loss\n",
        "        train_loss += loss.item() * data.size(0)\n",
        "        \n",
        "        \n",
        "    ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        "    model.eval()\n",
        "    for data,label in valid_loader:\n",
        "        # Forward\n",
        "        output = model(data.to(device))\n",
        "        loss = loss_func(output,label.to(device))\n",
        "        \n",
        "        valid_loss = loss.item() * data.size(0)\n",
        "    \n",
        "    # Print training/validation statistics \n",
        "    # Calculate average loss over an epoch\n",
        "    train_loss = train_loss / len(train_loader.sampler)\n",
        "    valid_loss = valid_loss / len(valid_loader.sampler)\n",
        "    \n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        epoch+1, \n",
        "        train_loss,\n",
        "        valid_loss\n",
        "        ))\n",
        "    \n",
        "    # Save model if validation loss has decreased\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss))\n",
        "        torch.save(model.state_dict(), 'model.pt')\n",
        "        valid_loss_min = valid_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-5PuvLa11Tf",
        "outputId": "a8940340-1502-4519-875f-36719269eece"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('model.pt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wL_r95-11Tf",
        "outputId": "579dca82-108f-4905-b0b9-b742bd1959b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.333313\n",
            "\n",
            "Test Accuracy of     0: 82% (821/1000)\n",
            "Test Accuracy of     1: 97% (974/1000)\n",
            "Test Accuracy of     2: 71% (719/1000)\n",
            "Test Accuracy of     3: 92% (923/1000)\n",
            "Test Accuracy of     4: 88% (882/1000)\n",
            "Test Accuracy of     5: 96% (963/1000)\n",
            "Test Accuracy of     6: 71% (718/1000)\n",
            "Test Accuracy of     7: 96% (966/1000)\n",
            "Test Accuracy of     8: 97% (973/1000)\n",
            "Test Accuracy of     9: 95% (955/1000)\n",
            "\n",
            "Test Accuracy (Overall): 88% (8894/10000)\n"
          ]
        }
      ],
      "source": [
        "##################    \n",
        "# test the model #\n",
        "##################\n",
        "\n",
        "# initialize lists to monitor test loss and accuracy\n",
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "model.eval() # prep model for evaluation\n",
        "for data, target in test_loader:\n",
        "    # Forward\n",
        "    output = model.forward(data.to(device))\n",
        "    loss = loss_func(output, target.to(device))\n",
        "    \n",
        "    test_loss += loss.item()*data.size(0)\n",
        "    \n",
        "    # Convert output probabilities to predicted class\n",
        "    _, pred = torch.max(output, 1)\n",
        "    # compare predictions to true label\n",
        "    correct = np.squeeze(pred.eq(target.to(device).data.view_as(pred)))\n",
        "    \n",
        "    # Calculate test accuracy for each object class\n",
        "    for i in range(len(target)):\n",
        "        label = target.data[i]\n",
        "        class_correct[label] += correct[i].item()\n",
        "        class_total[label] += 1\n",
        "        \n",
        "# Calculate and print avg test loss\n",
        "test_loss = test_loss/len(test_loader.sampler)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "for i in range(10):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            str(i), 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7ISqkjmCPB1"
      },
      "source": [
        "### Task 2: Overfit it.\n",
        "Build a network that will overfit to this dataset. Demonstrate the overfitting in the appropriate way (e.g. plot loss and accurasy on train and test set w.r.t. network complexity).\n",
        "\n",
        "*Note:* you also might decrease the size of `train` dataset to enforce the overfitting and speed up the computations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ge7C_ulr11Tg",
        "outputId": "c0157a4b-b76f-4351-8652-9996bdfcedaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "source": [
        "# Let's decrease the size of train 4 times\n",
        "\n",
        "overfitted_train_index = train_index[:int(len(train_index)/8)]\n",
        "overfitted_train_sampler = SubsetRandomSampler(train_index)\n",
        "overfitted_train_loader = torch.utils.data.DataLoader(fmnist_dataset_train, \n",
        "                                           batch_size=128,\n",
        "                                           sampler=overfitted_train_sampler,\n",
        "                                           num_workers=num_workers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "H12uAWiGBwJx"
      },
      "outputs": [],
      "source": [
        "class OverfittingNeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_shape=28*28, num_classes=10, input_channels=1):\n",
        "        super(self.__class__, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(input_shape, 1024),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(1024, num_classes),\n",
        "            nn.LogSoftmax()\n",
        "        )\n",
        "        \n",
        "    def forward(self, inp):       \n",
        "        out = self.model(inp)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgXAKCpvCwqH",
        "outputId": "6241673d-f124-4bc5-abef-f7fcebd0302f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "           Flatten-1                  [-1, 784]               0\n",
            "            Linear-2                 [-1, 1024]         803,840\n",
            "              Tanh-3                 [-1, 1024]               0\n",
            "            Linear-4                 [-1, 1024]       1,049,600\n",
            "              Tanh-5                 [-1, 1024]               0\n",
            "            Linear-6                 [-1, 1024]       1,049,600\n",
            "              Tanh-7                 [-1, 1024]               0\n",
            "            Linear-8                 [-1, 1024]       1,049,600\n",
            "              Tanh-9                 [-1, 1024]               0\n",
            "           Linear-10                 [-1, 1024]       1,049,600\n",
            "             Tanh-11                 [-1, 1024]               0\n",
            "           Linear-12                 [-1, 1024]       1,049,600\n",
            "             Tanh-13                 [-1, 1024]               0\n",
            "           Linear-14                 [-1, 1024]       1,049,600\n",
            "             Tanh-15                 [-1, 1024]               0\n",
            "           Linear-16                 [-1, 1024]       1,049,600\n",
            "             Tanh-17                 [-1, 1024]               0\n",
            "           Linear-18                 [-1, 1024]       1,049,600\n",
            "             Tanh-19                 [-1, 1024]               0\n",
            "           Linear-20                 [-1, 1024]       1,049,600\n",
            "             Tanh-21                 [-1, 1024]               0\n",
            "           Linear-22                   [-1, 10]          10,250\n",
            "       LogSoftmax-23                   [-1, 10]               0\n",
            "================================================================\n",
            "Total params: 10,260,490\n",
            "Trainable params: 10,260,490\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.16\n",
            "Params size (MB): 39.14\n",
            "Estimated Total Size (MB): 39.31\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        }
      ],
      "source": [
        "torchsummary.summary(OverfittingNeuralNetwork().to(device), (28*28,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f7MNRl611Th",
        "outputId": "00f93ce7-2be9-4d38-cd4a-a7af431c9478"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 \tTraining Loss: 2.302895 \tValidation Loss: 0.018395 \tValidation average accuracy: 48.070236\n",
            "Validation loss decreased (inf --> 0.018395).  Saving model ...\n",
            "Epoch: 2 \tTraining Loss: 2.302668 \tValidation Loss: 0.018420 \tValidation average accuracy: 43.719250\n",
            "Epoch: 3 \tTraining Loss: 2.302448 \tValidation Loss: 0.018447 \tValidation average accuracy: 40.249449\n",
            "Epoch: 4 \tTraining Loss: 2.302233 \tValidation Loss: 0.018417 \tValidation average accuracy: 37.375125\n",
            "Epoch: 5 \tTraining Loss: 2.302019 \tValidation Loss: 0.018427 \tValidation average accuracy: 35.022831\n",
            "Epoch: 6 \tTraining Loss: 2.301808 \tValidation Loss: 0.018429 \tValidation average accuracy: 33.158116\n",
            "Epoch: 7 \tTraining Loss: 2.301595 \tValidation Loss: 0.018416 \tValidation average accuracy: 31.542284\n",
            "Epoch: 8 \tTraining Loss: 2.301379 \tValidation Loss: 0.018407 \tValidation average accuracy: 30.142520\n",
            "Epoch: 9 \tTraining Loss: 2.301159 \tValidation Loss: 0.018411 \tValidation average accuracy: 28.891910\n",
            "Epoch: 10 \tTraining Loss: 2.300933 \tValidation Loss: 0.018402 \tValidation average accuracy: 27.743610\n",
            "Epoch: 11 \tTraining Loss: 2.300699 \tValidation Loss: 0.018403 \tValidation average accuracy: 26.695298\n",
            "Epoch: 12 \tTraining Loss: 2.300455 \tValidation Loss: 0.018399 \tValidation average accuracy: 25.834284\n",
            "Epoch: 13 \tTraining Loss: 2.300200 \tValidation Loss: 0.018397 \tValidation average accuracy: 25.050758\n",
            "Epoch: 14 \tTraining Loss: 2.299929 \tValidation Loss: 0.018405 \tValidation average accuracy: 24.710201\n",
            "Epoch: 15 \tTraining Loss: 2.299641 \tValidation Loss: 0.018398 \tValidation average accuracy: 24.573096\n",
            "Epoch: 16 \tTraining Loss: 2.299333 \tValidation Loss: 0.018388 \tValidation average accuracy: 24.583138\n",
            "Validation loss decreased (0.018395 --> 0.018388).  Saving model ...\n",
            "Epoch: 17 \tTraining Loss: 2.299000 \tValidation Loss: 0.018387 \tValidation average accuracy: 24.569838\n",
            "Validation loss decreased (0.018388 --> 0.018387).  Saving model ...\n",
            "Epoch: 18 \tTraining Loss: 2.298639 \tValidation Loss: 0.018397 \tValidation average accuracy: 24.633146\n",
            "Epoch: 19 \tTraining Loss: 2.298242 \tValidation Loss: 0.018392 \tValidation average accuracy: 24.761510\n",
            "Epoch: 20 \tTraining Loss: 2.297805 \tValidation Loss: 0.018380 \tValidation average accuracy: 24.882735\n",
            "Validation loss decreased (0.018387 --> 0.018380).  Saving model ...\n",
            "Epoch: 21 \tTraining Loss: 2.297318 \tValidation Loss: 0.018374 \tValidation average accuracy: 25.004810\n",
            "Validation loss decreased (0.018380 --> 0.018374).  Saving model ...\n",
            "Epoch: 22 \tTraining Loss: 2.296771 \tValidation Loss: 0.018370 \tValidation average accuracy: 25.225121\n",
            "Validation loss decreased (0.018374 --> 0.018370).  Saving model ...\n",
            "Epoch: 23 \tTraining Loss: 2.296150 \tValidation Loss: 0.018355 \tValidation average accuracy: 25.455239\n",
            "Validation loss decreased (0.018370 --> 0.018355).  Saving model ...\n",
            "Epoch: 24 \tTraining Loss: 2.295438 \tValidation Loss: 0.018367 \tValidation average accuracy: 25.763624\n",
            "Epoch: 25 \tTraining Loss: 2.294610 \tValidation Loss: 0.018349 \tValidation average accuracy: 26.233193\n",
            "Validation loss decreased (0.018355 --> 0.018349).  Saving model ...\n",
            "Epoch: 26 \tTraining Loss: 2.293635 \tValidation Loss: 0.018349 \tValidation average accuracy: 26.659743\n",
            "Epoch: 27 \tTraining Loss: 2.292467 \tValidation Loss: 0.018345 \tValidation average accuracy: 27.118242\n",
            "Validation loss decreased (0.018349 --> 0.018345).  Saving model ...\n",
            "Epoch: 28 \tTraining Loss: 2.291042 \tValidation Loss: 0.018320 \tValidation average accuracy: 27.573304\n",
            "Validation loss decreased (0.018345 --> 0.018320).  Saving model ...\n",
            "Epoch: 29 \tTraining Loss: 2.289263 \tValidation Loss: 0.018301 \tValidation average accuracy: 28.019621\n",
            "Validation loss decreased (0.018320 --> 0.018301).  Saving model ...\n",
            "Epoch: 30 \tTraining Loss: 2.286979 \tValidation Loss: 0.018303 \tValidation average accuracy: 28.488752\n",
            "Epoch: 31 \tTraining Loss: 2.283948 \tValidation Loss: 0.018262 \tValidation average accuracy: 28.925897\n",
            "Validation loss decreased (0.018301 --> 0.018262).  Saving model ...\n",
            "Epoch: 32 \tTraining Loss: 2.279748 \tValidation Loss: 0.018231 \tValidation average accuracy: 29.333540\n",
            "Validation loss decreased (0.018262 --> 0.018231).  Saving model ...\n",
            "Epoch: 33 \tTraining Loss: 2.273597 \tValidation Loss: 0.018161 \tValidation average accuracy: 29.673665\n",
            "Validation loss decreased (0.018231 --> 0.018161).  Saving model ...\n",
            "Epoch: 34 \tTraining Loss: 2.263886 \tValidation Loss: 0.018032 \tValidation average accuracy: 29.880921\n",
            "Validation loss decreased (0.018161 --> 0.018032).  Saving model ...\n",
            "Epoch: 35 \tTraining Loss: 2.246877 \tValidation Loss: 0.017934 \tValidation average accuracy: 29.905811\n",
            "Validation loss decreased (0.018032 --> 0.017934).  Saving model ...\n",
            "Epoch: 36 \tTraining Loss: 2.212360 \tValidation Loss: 0.017419 \tValidation average accuracy: 29.761162\n",
            "Validation loss decreased (0.017934 --> 0.017419).  Saving model ...\n",
            "Epoch: 37 \tTraining Loss: 2.127945 \tValidation Loss: 0.016528 \tValidation average accuracy: 29.560687\n",
            "Validation loss decreased (0.017419 --> 0.016528).  Saving model ...\n",
            "Epoch: 38 \tTraining Loss: 1.931542 \tValidation Loss: 0.014048 \tValidation average accuracy: 29.284310\n",
            "Validation loss decreased (0.016528 --> 0.014048).  Saving model ...\n",
            "Epoch: 39 \tTraining Loss: 1.755974 \tValidation Loss: 0.013364 \tValidation average accuracy: 29.094325\n",
            "Validation loss decreased (0.014048 --> 0.013364).  Saving model ...\n",
            "Epoch: 40 \tTraining Loss: 1.698120 \tValidation Loss: 0.013709 \tValidation average accuracy: 29.083523\n",
            "Epoch: 41 \tTraining Loss: 1.671789 \tValidation Loss: 0.013290 \tValidation average accuracy: 28.911308\n",
            "Validation loss decreased (0.013364 --> 0.013290).  Saving model ...\n",
            "Epoch: 42 \tTraining Loss: 1.654645 \tValidation Loss: 0.013195 \tValidation average accuracy: 28.772141\n",
            "Validation loss decreased (0.013290 --> 0.013195).  Saving model ...\n",
            "Epoch: 43 \tTraining Loss: 1.640580 \tValidation Loss: 0.013675 \tValidation average accuracy: 28.677416\n",
            "Epoch: 44 \tTraining Loss: 1.625935 \tValidation Loss: 0.012766 \tValidation average accuracy: 28.598246\n",
            "Validation loss decreased (0.013195 --> 0.012766).  Saving model ...\n",
            "Epoch: 45 \tTraining Loss: 1.607891 \tValidation Loss: 0.012775 \tValidation average accuracy: 28.526004\n",
            "Epoch: 46 \tTraining Loss: 1.582235 \tValidation Loss: 0.013067 \tValidation average accuracy: 28.509547\n",
            "Epoch: 47 \tTraining Loss: 1.542163 \tValidation Loss: 0.012127 \tValidation average accuracy: 28.607724\n",
            "Validation loss decreased (0.012766 --> 0.012127).  Saving model ...\n",
            "Epoch: 48 \tTraining Loss: 1.479518 \tValidation Loss: 0.011863 \tValidation average accuracy: 28.771657\n",
            "Validation loss decreased (0.012127 --> 0.011863).  Saving model ...\n",
            "Epoch: 49 \tTraining Loss: 1.398948 \tValidation Loss: 0.010402 \tValidation average accuracy: 29.102944\n",
            "Validation loss decreased (0.011863 --> 0.010402).  Saving model ...\n",
            "Epoch: 50 \tTraining Loss: 1.323663 \tValidation Loss: 0.010472 \tValidation average accuracy: 29.502347\n",
            "CPU times: user 4min 16s, sys: 1min, total: 5min 16s\n",
            "Wall time: 9min 46s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "overfitted_model = OverfittingNeuralNetwork().to(device)\n",
        "opt = torch.optim.SGD(overfitted_model.parameters(),lr = 0.001)\n",
        "loss_func = nn.NLLLoss()\n",
        "\n",
        "n_epochs = 50\n",
        "valid_loss_min = np.Inf  \n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "val_accs = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss = 0\n",
        "    valid_loss = 0\n",
        "    \n",
        "    # To compute then validation accuracy\n",
        "    val_class_correct = list(0. for i in range(10))\n",
        "    val_class_total = list(0. for i in range(10))\n",
        "\n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    overfitted_model.train()\n",
        "    for data,label in overfitted_train_loader:\n",
        "        opt.zero_grad()\n",
        "        \n",
        "        # Forward\n",
        "        output = overfitted_model(data.to(device))\n",
        "        loss = loss_func(output,label.to(device))\n",
        "        \n",
        "        # Backward\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        \n",
        "        # update running training loss\n",
        "        train_loss += loss.item() * data.size(0)\n",
        "        \n",
        "        \n",
        "    ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        "    overfitted_model.eval()\n",
        "    for data,label in valid_loader:\n",
        "        # Forward\n",
        "        output = overfitted_model(data.to(device))\n",
        "        loss = loss_func(output,label.to(device))\n",
        "        \n",
        "        valid_loss = loss.item() * data.size(0)\n",
        "        \n",
        "        # Convert output probabilities to predicted class\n",
        "        pred = torch.argmax(output, dim=1)\n",
        "        # Compare predictions to true label\n",
        "        correct = np.squeeze(pred.eq(label.to(device).data.view_as(pred)))\n",
        "    \n",
        "        # Calculate test accuracy for each object class\n",
        "        for i in range(len(target)):\n",
        "            label = target.data[i]\n",
        "            class_correct[label] += correct[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "    # Print training/validation statistics \n",
        "    # Calculate average loss over an epoch\n",
        "    train_loss = train_loss / len(train_loader.sampler)\n",
        "    valid_loss = valid_loss / len(valid_loader.sampler)\n",
        "    \n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    val_avrg_acc = 100. * np.sum(class_correct) / np.sum(class_total)\n",
        "    val_accs.append(val_avrg_acc)\n",
        "\n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\tValidation average accuracy: {:.6f}'.format(\n",
        "        epoch+1, \n",
        "        train_loss,\n",
        "        valid_loss, \n",
        "        val_avrg_acc\n",
        "        ))\n",
        "    \n",
        "    # Save model if validation loss has decreased\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss))\n",
        "        torch.save(overfitted_model.state_dict(), 'overfitted_model.pt')\n",
        "        valid_loss_min = valid_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "G9b6ddjL11Th",
        "outputId": "1e203c9d-7c3d-4f67-c1cf-93477595d173"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Learning score')"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x432 with 2 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, c=\"green\", label=\"train\")\n",
        "plt.plot(valid_losses, c=\"red\", label=\"validation\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Learning score\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(val_accs, c=\"purple\", label=\"validation accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Learning score\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSXc0tfo11Tj",
        "outputId": "94577887-aed1-4077-f0c9-1cd35f7ac1c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "overfitted_model.load_state_dict(torch.load('overfitted_model.pt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qi45shND11Tj",
        "outputId": "fe8df3fd-65f2-4724-8c36-27f5d226983f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 1.364035\n",
            "\n",
            "Test Accuracy of     0: 40% (403/1000)\n",
            "Test Accuracy of     1: 95% (957/1000)\n",
            "Test Accuracy of     2: 68% (689/1000)\n",
            "Test Accuracy of     3:  0% ( 9/1000)\n",
            "Test Accuracy of     4: 18% (186/1000)\n",
            "Test Accuracy of     5:  4% (45/1000)\n",
            "Test Accuracy of     6:  0% ( 5/1000)\n",
            "Test Accuracy of     7: 50% (507/1000)\n",
            "Test Accuracy of     8: 82% (827/1000)\n",
            "Test Accuracy of     9: 95% (950/1000)\n",
            "\n",
            "Test Accuracy (Overall): 45% (4578/10000)\n"
          ]
        }
      ],
      "source": [
        "##################    \n",
        "# test the model #\n",
        "##################\n",
        "\n",
        "# initialize lists to monitor test loss and accuracy\n",
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "overfitted_model.eval() # prep model for evaluation\n",
        "for data, target in test_loader:\n",
        "    # Forward\n",
        "    output = overfitted_model(data.to(device))\n",
        "    loss = loss_func(output, target.to(device))\n",
        "    \n",
        "    test_loss += loss.item()*data.size(0)\n",
        "    \n",
        "    # Convert output probabilities to predicted class\n",
        "    _, pred = torch.max(output, 1)\n",
        "    # compare predictions to true label\n",
        "    correct = np.squeeze(pred.eq(target.to(device).data.view_as(pred)))\n",
        "    \n",
        "    # Calculate test accuracy for each object class\n",
        "    for i in range(len(target)):\n",
        "        label = target.data[i]\n",
        "        class_correct[label] += correct[i].item()\n",
        "        class_total[label] += 1\n",
        "        \n",
        "# Calculate and print avg test loss\n",
        "test_loss = test_loss/len(test_loader.sampler)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "for i in range(10):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            str(i), 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg8OMUCp11Tj"
      },
      "source": [
        "### Task 3: Fix it.\n",
        "Fix the overfitted network from the previous step (at least partially) by using regularization techniques (Dropout/Batchnorm/...) and demonstrate the results. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "YeNIMjsGO9sO"
      },
      "outputs": [],
      "source": [
        "class FixedNeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_shape=28*28, num_classes=10, input_channels=1):\n",
        "        super(self.__class__, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(input_shape, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(1024, num_classes),\n",
        "            nn.LogSoftmax()\n",
        "        )\n",
        "        \n",
        "    def forward(self, inp):       \n",
        "        out = self.model(inp)\n",
        "        return out\n",
        "        \n",
        "    def forward(self, inp):       \n",
        "        out = self.model(inp)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgDIfM_P11Tj",
        "outputId": "69598af4-d1a3-4602-eb58-37606a9687a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "           Flatten-1                  [-1, 784]               0\n",
            "            Linear-2                 [-1, 1024]         803,840\n",
            "       BatchNorm1d-3                 [-1, 1024]           2,048\n",
            "              Tanh-4                 [-1, 1024]               0\n",
            "           Dropout-5                 [-1, 1024]               0\n",
            "            Linear-6                 [-1, 1024]       1,049,600\n",
            "       BatchNorm1d-7                 [-1, 1024]           2,048\n",
            "              Tanh-8                 [-1, 1024]               0\n",
            "           Dropout-9                 [-1, 1024]               0\n",
            "           Linear-10                 [-1, 1024]       1,049,600\n",
            "      BatchNorm1d-11                 [-1, 1024]           2,048\n",
            "             Tanh-12                 [-1, 1024]               0\n",
            "          Dropout-13                 [-1, 1024]               0\n",
            "           Linear-14                 [-1, 1024]       1,049,600\n",
            "      BatchNorm1d-15                 [-1, 1024]           2,048\n",
            "             Tanh-16                 [-1, 1024]               0\n",
            "          Dropout-17                 [-1, 1024]               0\n",
            "           Linear-18                 [-1, 1024]       1,049,600\n",
            "      BatchNorm1d-19                 [-1, 1024]           2,048\n",
            "             Tanh-20                 [-1, 1024]               0\n",
            "          Dropout-21                 [-1, 1024]               0\n",
            "           Linear-22                 [-1, 1024]       1,049,600\n",
            "      BatchNorm1d-23                 [-1, 1024]           2,048\n",
            "             Tanh-24                 [-1, 1024]               0\n",
            "          Dropout-25                 [-1, 1024]               0\n",
            "           Linear-26                 [-1, 1024]       1,049,600\n",
            "      BatchNorm1d-27                 [-1, 1024]           2,048\n",
            "             Tanh-28                 [-1, 1024]               0\n",
            "          Dropout-29                 [-1, 1024]               0\n",
            "           Linear-30                 [-1, 1024]       1,049,600\n",
            "      BatchNorm1d-31                 [-1, 1024]           2,048\n",
            "             Tanh-32                 [-1, 1024]               0\n",
            "          Dropout-33                 [-1, 1024]               0\n",
            "           Linear-34                 [-1, 1024]       1,049,600\n",
            "      BatchNorm1d-35                 [-1, 1024]           2,048\n",
            "             Tanh-36                 [-1, 1024]               0\n",
            "          Dropout-37                 [-1, 1024]               0\n",
            "           Linear-38                 [-1, 1024]       1,049,600\n",
            "      BatchNorm1d-39                 [-1, 1024]           2,048\n",
            "             Tanh-40                 [-1, 1024]               0\n",
            "          Dropout-41                 [-1, 1024]               0\n",
            "           Linear-42                   [-1, 10]          10,250\n",
            "       LogSoftmax-43                   [-1, 10]               0\n",
            "================================================================\n",
            "Total params: 10,280,970\n",
            "Trainable params: 10,280,970\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.32\n",
            "Params size (MB): 39.22\n",
            "Estimated Total Size (MB): 39.54\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        }
      ],
      "source": [
        "torchsummary.summary(FixedNeuralNetwork().to(device), (28*28,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c40f7d2c-90ba-4e57-b056-c566cfa21276",
        "id": "fhbw9IubQBYg"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 \tTraining Loss: 1.438932 \tValidation Loss: 0.005632\n",
            "Validation loss decreased (inf --> 0.005632).  Saving model ...\n",
            "Epoch: 2 \tTraining Loss: 0.831934 \tValidation Loss: 0.005660\n",
            "Epoch: 3 \tTraining Loss: 0.692067 \tValidation Loss: 0.005968\n",
            "Epoch: 4 \tTraining Loss: 0.628057 \tValidation Loss: 0.004815\n",
            "Validation loss decreased (0.005632 --> 0.004815).  Saving model ...\n",
            "Epoch: 5 \tTraining Loss: 0.590155 \tValidation Loss: 0.005880\n",
            "Epoch: 6 \tTraining Loss: 0.559933 \tValidation Loss: 0.003315\n",
            "Validation loss decreased (0.004815 --> 0.003315).  Saving model ...\n",
            "Epoch: 7 \tTraining Loss: 0.539285 \tValidation Loss: 0.003336\n",
            "Epoch: 8 \tTraining Loss: 0.525189 \tValidation Loss: 0.002642\n",
            "Validation loss decreased (0.003315 --> 0.002642).  Saving model ...\n",
            "Epoch: 9 \tTraining Loss: 0.511967 \tValidation Loss: 0.003472\n",
            "Epoch: 10 \tTraining Loss: 0.497003 \tValidation Loss: 0.002615\n",
            "Validation loss decreased (0.002642 --> 0.002615).  Saving model ...\n",
            "Epoch: 11 \tTraining Loss: 0.490518 \tValidation Loss: 0.003603\n",
            "Epoch: 12 \tTraining Loss: 0.482069 \tValidation Loss: 0.002104\n",
            "Validation loss decreased (0.002615 --> 0.002104).  Saving model ...\n",
            "Epoch: 13 \tTraining Loss: 0.473898 \tValidation Loss: 0.003554\n",
            "Epoch: 14 \tTraining Loss: 0.467119 \tValidation Loss: 0.003356\n",
            "Epoch: 15 \tTraining Loss: 0.455764 \tValidation Loss: 0.002892\n",
            "Epoch: 16 \tTraining Loss: 0.458248 \tValidation Loss: 0.004075\n",
            "Epoch: 17 \tTraining Loss: 0.452019 \tValidation Loss: 0.003565\n",
            "Epoch: 18 \tTraining Loss: 0.445339 \tValidation Loss: 0.002294\n",
            "Epoch: 19 \tTraining Loss: 0.442454 \tValidation Loss: 0.002827\n",
            "Epoch: 20 \tTraining Loss: 0.435977 \tValidation Loss: 0.002774\n",
            "Epoch: 21 \tTraining Loss: 0.428786 \tValidation Loss: 0.004152\n",
            "Epoch: 22 \tTraining Loss: 0.426556 \tValidation Loss: 0.003506\n",
            "Epoch: 23 \tTraining Loss: 0.423879 \tValidation Loss: 0.002343\n",
            "Epoch: 24 \tTraining Loss: 0.420149 \tValidation Loss: 0.002929\n",
            "Epoch: 25 \tTraining Loss: 0.417937 \tValidation Loss: 0.003215\n",
            "Epoch: 26 \tTraining Loss: 0.413679 \tValidation Loss: 0.001915\n",
            "Validation loss decreased (0.002104 --> 0.001915).  Saving model ...\n",
            "Epoch: 27 \tTraining Loss: 0.410407 \tValidation Loss: 0.003845\n",
            "Epoch: 28 \tTraining Loss: 0.406366 \tValidation Loss: 0.003996\n",
            "Epoch: 29 \tTraining Loss: 0.406140 \tValidation Loss: 0.004010\n",
            "Epoch: 30 \tTraining Loss: 0.399215 \tValidation Loss: 0.002867\n",
            "Epoch: 31 \tTraining Loss: 0.397974 \tValidation Loss: 0.002312\n",
            "Epoch: 32 \tTraining Loss: 0.399390 \tValidation Loss: 0.003083\n",
            "Epoch: 33 \tTraining Loss: 0.397030 \tValidation Loss: 0.004620\n",
            "Epoch: 34 \tTraining Loss: 0.391367 \tValidation Loss: 0.003094\n",
            "Epoch: 35 \tTraining Loss: 0.387418 \tValidation Loss: 0.003443\n",
            "Epoch: 36 \tTraining Loss: 0.388778 \tValidation Loss: 0.002446\n",
            "Epoch: 37 \tTraining Loss: 0.385774 \tValidation Loss: 0.002524\n",
            "Epoch: 38 \tTraining Loss: 0.382029 \tValidation Loss: 0.005206\n",
            "Epoch: 39 \tTraining Loss: 0.381796 \tValidation Loss: 0.002415\n",
            "Epoch: 40 \tTraining Loss: 0.380929 \tValidation Loss: 0.002382\n",
            "Epoch: 41 \tTraining Loss: 0.375922 \tValidation Loss: 0.003779\n",
            "Epoch: 42 \tTraining Loss: 0.375258 \tValidation Loss: 0.001500\n",
            "Validation loss decreased (0.001915 --> 0.001500).  Saving model ...\n",
            "Epoch: 43 \tTraining Loss: 0.374211 \tValidation Loss: 0.002963\n",
            "Epoch: 44 \tTraining Loss: 0.370562 \tValidation Loss: 0.003553\n",
            "Epoch: 45 \tTraining Loss: 0.367397 \tValidation Loss: 0.004185\n",
            "Epoch: 46 \tTraining Loss: 0.366397 \tValidation Loss: 0.001787\n",
            "Epoch: 47 \tTraining Loss: 0.365561 \tValidation Loss: 0.003538\n",
            "Epoch: 48 \tTraining Loss: 0.362103 \tValidation Loss: 0.001830\n",
            "Epoch: 49 \tTraining Loss: 0.361496 \tValidation Loss: 0.002334\n",
            "Epoch: 50 \tTraining Loss: 0.356600 \tValidation Loss: 0.003890\n",
            "CPU times: user 5min 24s, sys: 1min 1s, total: 6min 26s\n",
            "Wall time: 10min 31s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "fixed_model = FixedNeuralNetwork().to(device)\n",
        "opt = torch.optim.SGD(fixed_model.parameters(),lr = 0.001)\n",
        "loss_func = nn.NLLLoss()\n",
        "\n",
        "n_epochs = 50\n",
        "valid_loss_min = np.Inf  \n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss = 0\n",
        "    valid_loss = 0\n",
        "    \n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    fixed_model.train()\n",
        "    for data,label in train_loader:\n",
        "        opt.zero_grad()\n",
        "        \n",
        "        # Forward\n",
        "        output = fixed_model(data.to(device))\n",
        "        loss = loss_func(output,label.to(device))\n",
        "        \n",
        "        # Backward\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        \n",
        "        # update running training loss\n",
        "        train_loss += loss.item() * data.size(0)\n",
        "        \n",
        "        \n",
        "    ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        "    fixed_model.eval()\n",
        "    for data,label in valid_loader:\n",
        "        # Forward\n",
        "        output = fixed_model(data.to(device))\n",
        "        loss = loss_func(output,label.to(device))\n",
        "        \n",
        "        valid_loss = loss.item() * data.size(0)\n",
        "    \n",
        "    # Print training/validation statistics \n",
        "    # Calculate average loss over an epoch\n",
        "    train_loss = train_loss / len(train_loader.sampler)\n",
        "    valid_loss = valid_loss / len(valid_loader.sampler)\n",
        "    \n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        epoch+1, \n",
        "        train_loss,\n",
        "        valid_loss\n",
        "        ))\n",
        "    \n",
        "    # Save model if validation loss has decreased\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss))\n",
        "        torch.save(fixed_model.state_dict(), 'fixed_model.pt')\n",
        "        valid_loss_min = valid_loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "plt.plot(train_losses, c=\"green\", label=\"train\")\n",
        "plt.plot(valid_losses, c=\"red\", label=\"validation\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Learning score\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "R6RC6nB8RB-s",
        "outputId": "7c9e962f-86e4-4a5b-d31a-153e7df5ceb1"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Learning score')"
            ]
          },
          "metadata": {},
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_model.load_state_dict(torch.load('fixed_model.pt'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-cTwsVjRPFC",
        "outputId": "7d63b176-919c-4d36-843e-ab0d58d39ee8"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##################    \n",
        "# test the model #\n",
        "##################\n",
        "\n",
        "# initialize lists to monitor test loss and accuracy\n",
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "fixed_model.eval() # prep model for evaluation\n",
        "for data, target in test_loader:\n",
        "    # Forward\n",
        "    output = fixed_model(data.to(device))\n",
        "    loss = loss_func(output, target.to(device))\n",
        "    \n",
        "    test_loss += loss.item()*data.size(0)\n",
        "    \n",
        "    # Convert output probabilities to predicted class\n",
        "    _, pred = torch.max(output, 1)\n",
        "    # compare predictions to true label\n",
        "    correct = np.squeeze(pred.eq(target.to(device).data.view_as(pred)))\n",
        "    \n",
        "    # Calculate test accuracy for each object class\n",
        "    for i in range(len(target)):\n",
        "        label = target.data[i]\n",
        "        class_correct[label] += correct[i].item()\n",
        "        class_total[label] += 1\n",
        "        \n",
        "# Calculate and print avg test loss\n",
        "test_loss = test_loss/len(test_loader.sampler)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "for i in range(10):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            str(i), 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1lPvItiRbgC",
        "outputId": "8c46498b-a314-4c86-a8a4-6a37e61901cd"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.414761\n",
            "\n",
            "Test Accuracy of     0: 82% (822/1000)\n",
            "Test Accuracy of     1: 95% (957/1000)\n",
            "Test Accuracy of     2: 76% (764/1000)\n",
            "Test Accuracy of     3: 88% (880/1000)\n",
            "Test Accuracy of     4: 78% (788/1000)\n",
            "Test Accuracy of     5: 92% (921/1000)\n",
            "Test Accuracy of     6: 65% (650/1000)\n",
            "Test Accuracy of     7: 94% (945/1000)\n",
            "Test Accuracy of     8: 96% (969/1000)\n",
            "Test Accuracy of     9: 95% (951/1000)\n",
            "\n",
            "Test Accuracy (Overall): 86% (8647/10000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMui_uLJ7G0d"
      },
      "source": [
        "### Conclusions:\n",
        "_Write down small report with your conclusions and your ideas._"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Скажу честно у меня не получилось нормально переобучить сеть, хотя я перепробовал много разных способов, а именно:\n",
        "1. уменьшал размер выборки\n",
        "2. поиграл с количеством скрытых слоев и их размерами\n",
        "3. пробовал разные функции активации (ReLU, LeakyReLU, Tanh)\n",
        "4. использовал разные оптимизаторы(Adam, SGD)\n",
        "\n",
        "Поэтому я был бы очень признателен, если бы Вы сказали, что я делаю не так. \n",
        "\n",
        "P.S.: Если можете посоветовать какие-нибудь полезные статьи или литературу на эту тему, то еще раз буду признателен."
      ],
      "metadata": {
        "id": "NjZDrDYRdLNV"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Lab2_DL_part2_overfitting.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}